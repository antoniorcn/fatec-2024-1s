{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b84bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b026e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f13c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c07501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590a0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5726b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb63672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b894d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4dbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc2e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15bfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb2c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f0bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "681cd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies = pd.read_csv(\"../../../dados/movies_metadata.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b84d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separada a lingua apenas filmes em inglês\n",
    "# movies = movies[movies[\"original_language\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ea3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apenas estas colunas serão utilizadas\n",
    "# df = movies[[\"genres\", \"overview\", \"original_title\", \"original_language\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3277eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para extração do gênero usando json\n",
    "# def extract_genre( texto ):\n",
    "#     novo_texto = texto.replace(\"'\", '\"')\n",
    "#     lista = json.loads(novo_texto)\n",
    "#     if len(lista) > 0:\n",
    "#         return lista[0].get(\"name\", \"unknow\")\n",
    "#     return \"unknow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1e2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['genero'] = df[\"genres\"].apply(extract_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8539f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['genero'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7790bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecomm = pd.read_csv(\"../../../dados/ecommerceDataset.csv\", low_memory=False, names=['class', 'text'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760d295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ecomm[['text', 'class']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "854926b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_dict = {\n",
    "    \"aren't\": \"are not\", \"can't\": \"can not\", \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\", \"daren't\": \"dare not\", \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he's\": \"he is\",\n",
    "    \"how'd\": \"how had\", \"how're\": \"how are\", \"how's\": \"how is\",\n",
    "    \"how've\": \"how have\", \"i'd\": \"i had\", \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\", \"isn't\": \"is+ not\", \"it's\": \"it is\",\n",
    "    \"might've\": \"might have\", \"mightn't\": \"might not\", \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\", \"needn't\": \"need not\", \"oughtn't\": \"ought not\",\n",
    "    \"shan't\": \"shall not\", \"she'd\": \"she had\", \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\", \"shouldn't\": \"should not\", \"that'd\": \"that had\",\n",
    "    \"thats's\": \"that is\", \"there'd\": \"there had\", \"there's\": \"there is\",\n",
    "    \"they'd\": \"they had\", \"they're\": \"you are\", \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was+ not\", \"we'd\": \"we had\", \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\", \"weren't\": \"were not\", \"what'd\": \"what had\",\n",
    "    \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "    \"when'd\": \"when had\", \"when're\": \"when are\", \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\", \"where'd\": \"where had\", \"where're\": \"where are\",\n",
    "    \"where's\": \"where is\", \"where've\": \"where have\", \"who'd\": \"who had\",\n",
    "    \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "    \"why'd\": \"why had\", \"why're\": \"why are\", \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
    "    \"you're\": \"you are\", \"you've\": \"you have\", \"'cause\": \"because\", \n",
    "    \"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \n",
    "    \"could've\": \"could have\", \"he's\": \"he is\", \"how'll\": \"how will\",\n",
    "    \"i'll\": \"i will\", \"it'll\": \"it will\", \"it's\": \"it is\", \n",
    "    \"she'll\": \"she will\", \"she's\": \"she is\", \"that'll\": \"that will\",\n",
    "    \"there'll\": \"there will\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "    \"we'll\": \"we will\", \"we're\": \"we are\", \"what'll\": \"what will\",\n",
    "    \"when'll\": \"when will\", \"where'll\": \"where will\", \"who'll\": \"who will\",\n",
    "    \"yo're\": \"you are\", \"you'll\": \"you will\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb9b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trocar_contracoes( texto ):\n",
    "    novas_palavras = []\n",
    "    lista_palavras = texto.split(\" \")\n",
    "    for palavra in lista_palavras:\n",
    "        if palavra in contraction_dict:\n",
    "            palavra = contraction_dict[palavra]\n",
    "        novas_palavras.append(palavra)\n",
    "    return \" \".join(novas_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9df5efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparar o texto removendo caracteres especiais e pontuação\n",
    "def preparar_texto( texto ):\n",
    "    texto_minusculo = texto.lower()\n",
    "    mascara = str.maketrans(\"\\n\\r\\t\", \"   \", string.punctuation)\n",
    "    texto_limpo = texto_minusculo.translate(mascara)\n",
    "    texto_limpo = unidecode(texto_limpo)\n",
    "    return texto_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06932c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original:  SAF 'Floral' Framed Painting (Wood, 30 inch x 10 inch, Special Effect UV Print Textured, SAO297) Painting made up in synthetic frame with UV textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch (A perfect gift for your special ones).\n",
      "Texto sem contrações:  SAF 'Floral' Framed Painting (Wood, 30 inch x 10 inch, Special Effect UV Print Textured, SAO297) Painting made up in synthetic frame with UV textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch (A perfect gift for your special ones).\n",
      "Texto preparado:  saf floral framed painting wood 30 inch x 10 inch special effect uv print textured sao297 painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it this is an special series of paintings which makes your wall very beautiful and gives a royal touch a perfect gift for your special ones\n"
     ]
    }
   ],
   "source": [
    "texto_original = df['text'][1]\n",
    "sem_contracoes = trocar_contracoes(texto_original)\n",
    "print(\"Texto original: \", texto_original)\n",
    "print(\"Texto sem contrações: \", sem_contracoes)\n",
    "texto_preparado = preparar_texto(sem_contracoes)\n",
    "print(\"Texto preparado: \", texto_preparado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af7f6492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando texto: 2000\n",
      "Preparando texto: 4000\n",
      "Preparando texto: 6000\n",
      "Preparando texto: 8000\n",
      "Preparando texto: 10000\n",
      "Preparando texto: 12000\n",
      "Preparando texto: 14000\n",
      "Preparando texto: 16000\n",
      "Preparando texto: 18000\n",
      "Preparando texto: 20000\n",
      "Preparando texto: 22000\n",
      "Preparando texto: 24000\n",
      "Preparando texto: 26000\n",
      "Preparando texto: 28000\n",
      "Preparando texto: 30000\n",
      "Preparando texto: 32000\n",
      "Preparando texto: 34000\n",
      "Preparando texto: 36000\n",
      "Preparando texto: 38000\n",
      "Preparando texto: 40000\n",
      "Preparando texto: 42000\n",
      "Preparando texto: 44000\n",
      "Preparando texto: 46000\n",
      "Preparando texto: 48000\n",
      "Preparando texto: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_25912\\632697425.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_overview'] = df[\"text\"].apply(limpar_texto)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "def limpar_texto( texto ):\n",
    "    global count\n",
    "    texto_limpo = \"\"\n",
    "    if type(texto) == str:\n",
    "        texto_sem_contracoes = trocar_contracoes( texto )\n",
    "        texto_limpo = preparar_texto( texto_sem_contracoes )\n",
    "    count += 1\n",
    "    if count % 2000 == 0:\n",
    "        print(f\"Preparando texto: {count}\")\n",
    "    return texto_limpo\n",
    "\n",
    "df['clean_overview'] = df[\"text\"].apply(limpar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c200ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'painting mantra art street  jardin bird framed art print set of 4 black 10 x 10 inch colorcolor  black theme  jardin black   breath new life into your home and office with this original painting reprint these high quality printed canvas are of size 10 inch by 10 inch comes framed and ready to hang note print does not need any glass for protection and hence this comes without the glass'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_overview'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1307828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador = TfidfVectorizer(max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "138e77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = vetorizador.fit_transform(df['clean_overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1069e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = vetorizador.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bee6be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix = pd.DataFrame.sparse.from_spmatrix(bow, columns=vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c69c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f746a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_Y = encoder.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32e1afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow_matrix, encoded_Y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "facc762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9496298254891592"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=100, max_iter=1000)\n",
    "model.fit( train_X, train_Y )\n",
    "acuracia = model.score(test_X, test_Y)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b30eb8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9541248016922264"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(random_state=100)\n",
    "model.fit( train_X, train_Y )\n",
    "acuracia = model.score(test_X, test_Y)\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49dc06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
